{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08f7827-e763-4416-8cfd-66e6ee589266",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction â€“ Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fa49f-57ae-448f-acdf-c05fb7610398",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook continues the Titanic survival analysis by focusing on building and evaluating predictive models.  \n",
    "The cleaned and feature-enhanced dataset from the previous EDA notebook is used as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addfd70-bbb2-4358-9627-dfc5740673a8",
   "metadata": {},
   "source": [
    "## Load Processed Dataset\n",
    "\n",
    "We load the preprocessed DataFrame saved after the EDA phase.  \n",
    "It includes engineered features such as `FamilySize`, `Deck`, `LogFare`, and cleaned versions of `Age`, `Fare`, and `Embarked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f37e3d-33ba-4beb-88d6-7410a0dc3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "df = pd.read_csv(\"titanic_processed_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef483df6-5951-4360-bea8-27c7d61b4807",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We select a subset of relevant features that showed predictive power during EDA, including:\n",
    "- Passenger class (`Pclass`)\n",
    "- Gender (`Sex`)\n",
    "- Age, Fare, and FamilySize\n",
    "- Embarked port\n",
    "- Extracted cabin deck\n",
    "\n",
    "The target variable is `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e59bdad-80f2-4f35-8d6d-9bd0597cd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\n",
    "    \"FamilySize\", \"Deck\"\n",
    "]\n",
    "\n",
    "target = \"Survived\"\n",
    "\n",
    "df_model = df[features + [target]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9603c22-1e85-4688-8994-7a59007e5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(columns=[target])\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3773546-c82d-4600-892f-119995ac700c",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline\n",
    "\n",
    "We use `sklearn`'s `ColumnTransformer` and `Pipeline` to automate:\n",
    "- Imputation of missing values\n",
    "- Scaling of numerical features\n",
    "- One-hot encoding of categorical variables\n",
    "\n",
    "This ensures that the same preprocessing is applied consistently across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc2819f-3450-4913-a143-f1d94f583e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Fare\", \"FamilySize\"]\n",
    "categorical_features = [\"Pclass\", \"Sex\", \"Embarked\", \"Deck\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21bf03-4ff9-4aed-a87c-106f209e0b4b",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We train two models for comparison:\n",
    "- Logistic Regression (as a simple and interpretable baseline)\n",
    "- Random Forest Classifier (for higher accuracy and feature importance insights)\n",
    "\n",
    "Both models are evaluated on a hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc2b8a8a-7a1d-4f2e-b625-7b6af16c19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa8e4b-21f1-4792-b762-297ff7830a46",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We evaluate the models using:\n",
    "- Confusion Matrix\n",
    "- Precision, Recall, F1-Score\n",
    "- ROC-AUC Score\n",
    "\n",
    "These metrics help us understand both general accuracy and performance on the minority class (survivors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33e3df3-d18c-4033-9056-2a50d7b7e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Confusion Matrix:\n",
      "[[96 14]\n",
      " [23 46]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       110\n",
      "           1       0.77      0.67      0.71        69\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.77      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "ROC AUC: 0.8472\n",
      "\n",
      "===== Random Forest =====\n",
      "Confusion Matrix:\n",
      "[[95 15]\n",
      " [24 45]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       110\n",
      "           1       0.75      0.65      0.70        69\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.76      0.76       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n",
      "ROC AUC: 0.8354\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0780afa-5c50-4450-a082-3f0325e2988e",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "- Logistic Regression performs slightly better overall, especially in terms of ROC AUC and balanced precision/recall for the positive class.\n",
    "- Random Forest yields comparable results but does not outperform the simpler model in this case.\n",
    "- Both models tend to classify non-survivors more reliably than survivors, which is common in slightly imbalanced datasets.\n",
    "\n",
    "Further improvements could come from cross-validation, hyperparameter tuning, or additional feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
